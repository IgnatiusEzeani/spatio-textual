{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ET6wKFGP-SOG",
        "Kt1OnOCpD13Q",
        "COQgoH2iLOpz",
        "ApoODrTs87P8"
      ],
      "authorship_tag": "ABX9TyOY19cZRxcFLWgbTxqEeHFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/spatio-textual/blob/main/spatio_textual_package_a_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing `spatio-textual` Python package"
      ],
      "metadata": {
        "id": "QBrCPj878Txz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**spatio-textual**: a Python package for spatial entity recognition and verb relation extraction from text created by the [Spatial Narratives Project](https://spacetimenarratives.github.io/) and designed to support spatio-textual annotation, analysis and visualization in digital humanities projects, with initial applications to:\n",
        "\n",
        "- the *Corpus of Lake District Writing* (CLDW)\n",
        "- Holocaust survivors' testimonies (e.g., USC Shoah Foundation archives)\n",
        "\n",
        "This package leverages spaCy and gazetteer-based classification to identify and label spatial entities such as cities, countries, camps, and geographic nouns, and also extracts action-verb contexts involving these entities.\n"
      ],
      "metadata": {
        "id": "8OL1Nd-F8WEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Setting up\n",
        "Download `en_core_web_trf` spaCy model and install `spatio-textual` package.\n",
        "\n",
        "**_Note:_** *Please wait a while, this may take about 2 mins* 🕐\n"
      ],
      "metadata": {
        "id": "ET6wKFGP-SOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf\n",
        "!pip install -q git+https://github.com/SpaceTimeNarratives/spatio-textual.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuaB_QNJcoYc",
        "outputId": "7de51485-6ab4-4ad3-c028-e0344b452328"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-trf==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
            "  Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
            "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.11/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
            "Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.9/237.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (735 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.6/735.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, curated-tokenizers, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 spacy-curated-transformers-0.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for spatio-textual (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Importing the `spatio-textual` package\n",
        "Having successfully downloaded the spaCy model and installed the `spatio-textual` package, it can now be imported and used in a Python environment to process text.\n",
        "\n",
        "*Again, this may take about a minute too, sorry...*"
      ],
      "metadata": {
        "id": "Kt1OnOCpD13Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1PJGz3edrWZR"
      },
      "outputs": [],
      "source": [
        "import spatio_textual"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `spatio-textual` package has the `annotate` module with functions `annotate_text` which does the job of identifying and labelling spatial entities. So we can import the function directly as below..."
      ],
      "metadata": {
        "id": "x2PfuuwaJcFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spatio_textual.annotate import annotate_text"
      ],
      "metadata": {
        "id": "1YS6j_-iKZKU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Annotating spatial entities"
      ],
      "metadata": {
        "id": "COQgoH2iLOpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beyond the typical labels for the named entity recognition task [`PERSON`, `ORG`, `LOC`, `DATE`], we have defined a set of entity labels that are relevant for our work as shown below:\n",
        "\n",
        "| Tag          | Description                                                  |\n",
        "| ------------ | ------------------------------------------------------------ |\n",
        "| `PERSON`     | A named person                                               |\n",
        "| `CONTINENT`  | A continent name (e.g. “Europe”, “Asia”)                     |\n",
        "| `COUNTRY`    | A country name (e.g. “Germany”, “Czechoslovakia”)            |\n",
        "| `US-STATE`   | A U.S. state name (e.g. “California”, “New York”)            |\n",
        "| `CITY`       | A city name (e.g. “Berlin”, “London”,  when classified)     |\n",
        "| `CAMP`       | A Holocaust-camp name e.g. “Auschwitz” (from your custom list)                |\n",
        "| `PLACE`      | Other place-type entities not matched above                  |\n",
        "| `GEONOUN`    | Generic geographic nouns (e.g. “valley”, “moor”)             |\n",
        "| `NON-VERBAL` | Terms like [PAUSES], [LAUGHS] in non-verbal list |\n",
        "| `FAMILY`     | Kinship terms (e.g. “mother”, “uncle”)                       |\n",
        "| `DATE`       | Temporal expressions (e.g. “March 9, 1996”)                  |\n",
        "| `TIME`       | Time-of-day expressions (e.g. “3 PM”)                        |\n",
        "| `EVENT`      | Named events (e.g. “D-Day”)                                  |\n",
        "| `QUANTITY`   | Numeric/measure expressions (e.g. “100 miles”)               |\n",
        "\n",
        "with the `annotate_text` function, we will now be able to label these entities in the given text as shown below"
      ],
      "metadata": {
        "id": "ErwJyCwoOn9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Annotating an example text"
      ],
      "metadata": {
        "id": "ApoODrTs87P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "\"During the summer of 1942, my family and I were deported from our home in Krakow to the Plaszow labor camp.\n",
        "We spent several difficult months there before being transferred to Auschwitz-Birkenau.\"\n",
        "\"\"\"\n",
        "\n",
        "result = annotate_text(text)"
      ],
      "metadata": {
        "id": "PK-CFbiTsUx6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, the output of the `annotate_text` function is stored in the variable `result` which is a dictionary containing `'entities'` and `'verb_data'`. We can look at the individual elements in each of them"
      ],
      "metadata": {
        "id": "6bolZK5_vytw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Let's look at `'entities'`...\n",
        "print(\"Entities:\")\n",
        "display(result['entities'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "CS4v-HoKWrC0",
        "outputId": "430a7bb4-f59e-4218-a7e3-5a2533aa7530",
        "cellView": "form"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'start_char': 9, 'token': 'the summer of 1942', 'tag': 'DATE'},\n",
              " {'start_char': 76, 'token': 'Krakow', 'tag': 'PLACE'},\n",
              " {'start_char': 90, 'token': 'Plaszow', 'tag': 'PLACE'},\n",
              " {'start_char': 98, 'token': 'labor camp', 'tag': 'GEONOUN'},\n",
              " {'start_char': 119, 'token': 'several difficult months', 'tag': 'DATE'},\n",
              " {'start_char': 178, 'token': 'Auschwitz', 'tag': 'CAMP'},\n",
              " {'start_char': 188, 'token': 'Birkenau', 'tag': 'CAMP'}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it contains a list of all identified entities in the text each of which is a dictionar containing the starting character position, the entity span, as well as its label."
      ],
      "metadata": {
        "id": "WhoRmoYfxtty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Now let's see the `'verb_data'`...\n",
        "\n",
        "print(\"\\nVerb Data:\")\n",
        "display(result['verb_data'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "cellView": "form",
        "id": "XUBboHN87ewr",
        "outputId": "7ee99dac-fdca-4df2-908b-ed9fa1ab40ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verb Data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'sent-id': 0,\n",
              "  'verb': 'deported',\n",
              "  'subject': 'family',\n",
              "  'object': 'the summer of 1942',\n",
              "  'sentence': '\\n\"During the summer of 1942, my family and I were deported from our home in Krakow to the Plaszow labor camp.'},\n",
              " {'sent-id': 1,\n",
              "  'verb': 'spent',\n",
              "  'subject': 'We',\n",
              "  'object': 'several difficult months',\n",
              "  'sentence': '\\nWe spent several difficult months there before being transferred to Auschwitz-Birkenau.\"'},\n",
              " {'sent-id': 1,\n",
              "  'verb': 'transferred',\n",
              "  'subject': '',\n",
              "  'object': 'Birkenau',\n",
              "  'sentence': '\\nWe spent several difficult months there before being transferred to Auschwitz-Birkenau.\"'}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotating text from file"
      ],
      "metadata": {
        "id": "ZRduMzA98pBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "456eaef0"
      },
      "source": [
        "You can read the content of a text file for annotation.\n",
        "\n",
        "The code below downloads the example text file, `example-text`, from the source repo [here](https://github.com/SpaceTimeNarratives/spatio-textual/blob/main/example-text) and annotates it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Download the example text:\n",
        "!wget -c -q \"https://raw.githubusercontent.com/SpaceTimeNarratives/spatio-textual/refs/heads/main/example-text\""
      ],
      "metadata": {
        "id": "M6r_Aq8-bL7c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Read and annotate the text:\n",
        "example_text = open(\"example-text\", 'r').read()\n",
        "file_result = annotate_text(example_text)"
      ],
      "metadata": {
        "id": "lUz5-ByMc0xJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Display annotation results:\n",
        "print(\"Entities from file:\")\n",
        "display(file_result['entities'])\n",
        "\n",
        "print(\"\\nVerb Data from file:\")\n",
        "display(file_result['verb_data'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "id": "IfrG3nYQ9P36",
        "outputId": "612382ff-41f5-456b-b4df-ae4698e136f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities from file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'start_char': 11, 'token': 'spring', 'tag': 'GEONOUN'},\n",
              " {'start_char': 75, 'token': 'village', 'tag': 'GEONOUN'},\n",
              " {'start_char': 88, 'token': 'Krakow', 'tag': 'PLACE'},\n",
              " {'start_char': 117, 'token': 'early in the morning', 'tag': 'TIME'},\n",
              " {'start_char': 235, 'token': 'days', 'tag': 'DATE'},\n",
              " {'start_char': 244, 'token': 'nights', 'tag': 'DATE'},\n",
              " {'start_char': 397, 'token': 'watchtowers', 'tag': 'GEONOUN'},\n",
              " {'start_char': 417, 'token': 'Auschwitz', 'tag': 'CAMP'},\n",
              " {'start_char': 485, 'token': 'children', 'tag': 'FAMILY'},\n",
              " {'start_char': 523, 'token': 'father', 'tag': 'FAMILY'},\n",
              " {'start_char': 540, 'token': 'mother', 'tag': 'FAMILY'},\n",
              " {'start_char': 578, 'token': 'camp', 'tag': 'GEONOUN'},\n",
              " {'start_char': 682, 'token': 'building', 'tag': 'GEONOUN'},\n",
              " {'start_char': 731, 'token': 'mother', 'tag': 'FAMILY'},\n",
              " {'start_char': 823, 'token': 'a few weeks later', 'tag': 'DATE'},\n",
              " {'start_char': 855, 'token': 'The days', 'tag': 'DATE'},\n",
              " {'start_char': 877, 'token': 'weeks', 'tag': 'DATE'},\n",
              " {'start_char': 884, 'token': 'weeks', 'tag': 'DATE'},\n",
              " {'start_char': 895, 'token': 'months', 'tag': 'DATE'},\n",
              " {'start_char': 1157, 'token': 'all these years', 'tag': 'DATE'},\n",
              " {'start_char': 1273, 'token': 'every day', 'tag': 'DATE'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verb Data from file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'sent-id': 0,\n",
              "  'verb': 'came',\n",
              "  'subject': 'they',\n",
              "  'object': 'us',\n",
              "  'sentence': 'It was the spring of 1943 when they came for us.'},\n",
              " {'sent-id': 1,\n",
              "  'verb': 'living',\n",
              "  'subject': 'We',\n",
              "  'object': 'village',\n",
              "  'sentence': 'We were living in a small village near Krakow.'},\n",
              " {'sent-id': 2,\n",
              "  'verb': 'arrived',\n",
              "  'subject': 'soldiers',\n",
              "  'object': '',\n",
              "  'sentence': 'The soldiers arrived early in the morning, shouting.'},\n",
              " {'sent-id': 2,\n",
              "  'verb': 'shouting',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'The soldiers arrived early in the morning, shouting.'},\n",
              " {'sent-id': 3,\n",
              "  'verb': 'rounded',\n",
              "  'subject': 'They',\n",
              "  'object': 'everyone',\n",
              "  'sentence': 'They rounded everyone up and forced us onto crowded trains.'},\n",
              " {'sent-id': 3,\n",
              "  'verb': 'forced',\n",
              "  'subject': '',\n",
              "  'object': 'us',\n",
              "  'sentence': 'They rounded everyone up and forced us onto crowded trains.'},\n",
              " {'sent-id': 5,\n",
              "  'verb': 'know',\n",
              "  'subject': 'We',\n",
              "  'object': '',\n",
              "  'sentence': \"We didn't know where we were going, but the fear was palpable.\"},\n",
              " {'sent-id': 5,\n",
              "  'verb': 'going',\n",
              "  'subject': 'we',\n",
              "  'object': '',\n",
              "  'sentence': \"We didn't know where we were going, but the fear was palpable.\"},\n",
              " {'sent-id': 7,\n",
              "  'verb': 'arrived',\n",
              "  'subject': 'we',\n",
              "  'object': 'place',\n",
              "  'sentence': 'Finally, we arrived at a place with barbed wire fences and watchtowers.'},\n",
              " {'sent-id': 11,\n",
              "  'verb': 'saw',\n",
              "  'subject': 'I',\n",
              "  'object': 'father',\n",
              "  'sentence': 'I never saw my father again.'},\n",
              " {'sent-id': 12,\n",
              "  'verb': 'sent',\n",
              "  'subject': 'mother',\n",
              "  'object': 'camp',\n",
              "  'sentence': \"My mother and I were sent to the women's camp.\"},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'forced',\n",
              "  'subject': 'We',\n",
              "  'object': '',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'do',\n",
              "  'subject': '',\n",
              "  'object': 'labor',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'building',\n",
              "  'subject': '',\n",
              "  'object': 'roads',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'clearing',\n",
              "  'subject': '',\n",
              "  'object': 'rubble',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 17,\n",
              "  'verb': 'became',\n",
              "  'subject': 'mother',\n",
              "  'object': '',\n",
              "  'sentence': 'One day, my mother became very ill.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'tried',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'care',\n",
              "  'subject': '',\n",
              "  'object': 'her',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'was',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'do',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 19,\n",
              "  'verb': 'died',\n",
              "  'subject': 'She',\n",
              "  'object': '',\n",
              "  'sentence': 'She died a few weeks later.'},\n",
              " {'sent-id': 21,\n",
              "  'verb': 'blurred',\n",
              "  'subject': 'The days',\n",
              "  'object': 'weeks',\n",
              "  'sentence': 'The days blurred into weeks, weeks into months.'},\n",
              " {'sent-id': 23,\n",
              "  'verb': 'deemed',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              " {'sent-id': 23,\n",
              "  'verb': 'work',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              " {'sent-id': 23,\n",
              "  'verb': 'sent',\n",
              "  'subject': 'those',\n",
              "  'object': 'chambers',\n",
              "  'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              " {'sent-id': 24,\n",
              "  'verb': 'know',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': \"I don't know how I survived.\"},\n",
              " {'sent-id': 24,\n",
              "  'verb': 'survived',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': \"I don't know how I survived.\"},\n",
              " {'sent-id': 27,\n",
              "  'verb': 'knew',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': 'The hunger, the cold, the constant fear, the loss of everything I ever knew.'},\n",
              " {'sent-id': 28,\n",
              "  'verb': 'carry',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': \"It's a burden I carry every day.\"}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Another way to this is by uploading your file using the file icon in the left sidebar. Then, replace `\"your_file.txt\"` with the name of your uploaded file and run the code cell."
      ],
      "metadata": {
        "id": "iY0BiQkrcRVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotating a list of texts"
      ],
      "metadata": {
        "id": "v-NkvcFLE8H2"
      }
    }
  ]
}