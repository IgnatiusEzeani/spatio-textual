{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ET6wKFGP-SOG",
        "Kt1OnOCpD13Q",
        "COQgoH2iLOpz",
        "ApoODrTs87P8"
      ],
      "authorship_tag": "ABX9TyNRzOwaYrVyWS/N0X5WJK5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/spatio-textual/blob/main/spatio_textual_package_a_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing `spatio-textual` Python package"
      ],
      "metadata": {
        "id": "QBrCPj878Txz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**spatio-textual**: a Python package for spatial entity recognition and verb relation extraction from text created by the [Spatial Narratives Project](https://spacetimenarratives.github.io/) and designed to support spatio-textual annotation, analysis and visualization in digital humanities projects, with initial applications to:\n",
        "\n",
        "- the *Corpus of Lake District Writing* (CLDW)\n",
        "- Holocaust survivors' testimonies (e.g., USC Shoah Foundation archives)\n",
        "\n",
        "This package leverages spaCy and gazetteer-based classification to identify and label spatial entities such as cities, countries, camps, and geographic nouns, and also extracts action-verb contexts involving these entities.\n"
      ],
      "metadata": {
        "id": "8OL1Nd-F8WEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Setting up\n",
        "Download `en_core_web_trf` spaCy model and install `spatio-textual` package.\n",
        "\n",
        "**_Note:_** *Please wait a while, this may take a minute or 2...* 🕐\n"
      ],
      "metadata": {
        "id": "ET6wKFGP-SOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf\n",
        "!pip install -q git+https://github.com/SpaceTimeNarratives/spatio-textual.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuaB_QNJcoYc",
        "outputId": "e28851f0-2aa3-418e-fb21-466b6de1b092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-trf==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
            "  Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
            "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_tokenizers-0.0.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.12/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
            "Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.9/237.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (734 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.0/734.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
            "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for spatio-textual (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Importing the `spatio-textual` package\n",
        "Having successfully downloaded the spaCy model and installed the `spatio-textual` package, it can now be imported and used in a Python environment to process text.\n",
        "\n",
        "*Again, this may take about a minute too, sorry...*"
      ],
      "metadata": {
        "id": "Kt1OnOCpD13Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1PJGz3edrWZR"
      },
      "outputs": [],
      "source": [
        "import spatio_textual"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `spatio-textual` package has the `annotate` module with functions `annotate_text`, `annotate_texts`, `chunk_and_annotate_text`, `chunk_and_annotate_file` which identifies and labels spatial entities in text inputs of different formats.\n",
        "\n",
        "So we can import the functions directly as below"
      ],
      "metadata": {
        "id": "x2PfuuwaJcFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spatio_textual.annotate import (\n",
        "    annotate_text,            # annotates a single text\n",
        "    annotate_texts,           # annotates a collection of texts\n",
        "    chunk_and_annotate_text,  # chunks and annotates a text\n",
        "    chunk_and_annotate_file,  # chunks and annotates a file\n",
        ")"
      ],
      "metadata": {
        "id": "5zd_SQRQ8fSo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Annotating spatial entities"
      ],
      "metadata": {
        "id": "COQgoH2iLOpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beyond the typical labels for the named entity recognition task [`PERSON`, `ORG`, `LOC`, `DATE`], we have defined a set of entity labels that are relevant for our work as shown below:\n",
        "\n",
        "| Tag          | Description                                                  |\n",
        "| ------------ | ------------------------------------------------------------ |\n",
        "| `PERSON`     | A named person                                               |\n",
        "| `CONTINENT`  | A continent name (e.g. “Europe”, “Asia”)                     |\n",
        "| `COUNTRY`    | A country name (e.g. “Germany”, “Czechoslovakia”)            |\n",
        "| `US-STATE`   | A U.S. state name (e.g. “California”, “New York”)            |\n",
        "| `CITY`       | A city name (e.g. “Berlin”, “London”,  when classified)     |\n",
        "| `CAMP`       | A Holocaust-camp name e.g. “Auschwitz” (from your custom list)                |\n",
        "| `PLACE`      | Other place-type entities not matched above                  |\n",
        "| `GEONOUN`    | Generic geographic nouns (e.g. “valley”, “moor”)             |\n",
        "| `NON-VERBAL` | Terms like [PAUSES], [LAUGHS] in non-verbal list |\n",
        "| `FAMILY`     | Kinship terms (e.g. “mother”, “uncle”)                       |\n",
        "| `DATE`       | Temporal expressions (e.g. “March 9, 1996”)                  |\n",
        "| `TIME`       | Time-of-day expressions (e.g. “3 PM”)                        |\n",
        "| `EVENT`      | Named events (e.g. “D-Day”)                                  |\n",
        "| `QUANTITY`   | Numeric/measure expressions (e.g. “100 miles”)               |\n",
        "\n",
        "with the `annotate_text` function, we will now be able to label these entities in the given text as shown below"
      ],
      "metadata": {
        "id": "ErwJyCwoOn9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Annotating text"
      ],
      "metadata": {
        "id": "ApoODrTs87P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "\"During the summer of 1942, my family and I were deported from our home in Krakow to the Plaszow labor camp.\n",
        "We spent several difficult months there before being transferred to Auschwitz-Birkenau.\"\n",
        "\"\"\"\n",
        "\n",
        "result = annotate_text(text)"
      ],
      "metadata": {
        "id": "PK-CFbiTsUx6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, the output of the `annotate_text` function is stored in the variable `result` which is a dictionary containing `'entities'` and `'verb_data'`. We can look at the individual elements in each of them"
      ],
      "metadata": {
        "id": "6bolZK5_vytw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Let's look at `'entities'`...\n",
        "print(\"Entities:\")\n",
        "display(result['entities'])"
      ],
      "metadata": {
        "id": "CS4v-HoKWrC0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "22c1f8ed-a505-43c5-ee04-14b612dd9bbc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'start_char': 9, 'token': 'the summer of 1942', 'tag': 'DATE'},\n",
              " {'start_char': 76, 'token': 'Krakow', 'tag': 'PLACE'},\n",
              " {'start_char': 90, 'token': 'Plaszow', 'tag': 'PLACE'},\n",
              " {'start_char': 98, 'token': 'labor camp', 'tag': 'GEONOUN'},\n",
              " {'start_char': 119, 'token': 'several difficult months', 'tag': 'DATE'},\n",
              " {'start_char': 178, 'token': 'Auschwitz-Birkenau', 'tag': 'CAMP'}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it contains a list of all identified entities in the text each of which is a dictionar containing the starting character position, the entity span, as well as its label."
      ],
      "metadata": {
        "id": "WhoRmoYfxtty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Now let's see the `'verb_data'`...\n",
        "\n",
        "print(\"\\nVerb Data:\")\n",
        "display(result['verb_data'])"
      ],
      "metadata": {
        "id": "XUBboHN87ewr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "618e55dd-516a-4319-8f83-8f7c76ef422b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verb Data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotating text from file"
      ],
      "metadata": {
        "id": "ZRduMzA98pBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "456eaef0"
      },
      "source": [
        "You can read the content of a text file for annotation.\n",
        "\n",
        "The code below downloads the example text file, `example-text`, from the source repo [here](https://github.com/SpaceTimeNarratives/spatio-textual/blob/main/example-text) and annotates it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Download the example text:\n",
        "!wget -c -q \"https://raw.githubusercontent.com/SpaceTimeNarratives/spatio-textual/refs/heads/main/example-text\""
      ],
      "metadata": {
        "id": "M6r_Aq8-bL7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Read and annotate the text:\n",
        "example_text = open(\"example-text\", 'r').read()\n",
        "file_result = annotate_text(example_text)"
      ],
      "metadata": {
        "id": "lUz5-ByMc0xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##### Display annotation results:\n",
        "print(\"Entities from file:\")\n",
        "display(file_result['entities'])\n",
        "\n",
        "print(\"\\nVerb Data from file:\")\n",
        "display(file_result['verb_data'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IfrG3nYQ9P36",
        "outputId": "15371b52-081d-403a-b0fa-62471b3e5438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities from file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'start_char': 11, 'token': 'spring', 'tag': 'GEONOUN'},\n",
              " {'start_char': 75, 'token': 'village', 'tag': 'GEONOUN'},\n",
              " {'start_char': 88, 'token': 'Krakow', 'tag': 'PLACE'},\n",
              " {'start_char': 117, 'token': 'early in the morning', 'tag': 'TIME'},\n",
              " {'start_char': 235, 'token': 'days', 'tag': 'DATE'},\n",
              " {'start_char': 244, 'token': 'nights', 'tag': 'DATE'},\n",
              " {'start_char': 397, 'token': 'watchtowers', 'tag': 'GEONOUN'},\n",
              " {'start_char': 417, 'token': 'Auschwitz', 'tag': 'CAMP'},\n",
              " {'start_char': 485, 'token': 'children', 'tag': 'FAMILY'},\n",
              " {'start_char': 523, 'token': 'father', 'tag': 'FAMILY'},\n",
              " {'start_char': 540, 'token': 'mother', 'tag': 'FAMILY'},\n",
              " {'start_char': 578, 'token': 'camp', 'tag': 'GEONOUN'},\n",
              " {'start_char': 682, 'token': 'building', 'tag': 'GEONOUN'},\n",
              " {'start_char': 731, 'token': 'mother', 'tag': 'FAMILY'},\n",
              " {'start_char': 823, 'token': 'a few weeks later', 'tag': 'DATE'},\n",
              " {'start_char': 855, 'token': 'The days', 'tag': 'DATE'},\n",
              " {'start_char': 877, 'token': 'weeks', 'tag': 'DATE'},\n",
              " {'start_char': 884, 'token': 'weeks', 'tag': 'DATE'},\n",
              " {'start_char': 895, 'token': 'months', 'tag': 'DATE'},\n",
              " {'start_char': 1157, 'token': 'all these years', 'tag': 'DATE'},\n",
              " {'start_char': 1273, 'token': 'every day', 'tag': 'DATE'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verb Data from file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'sent-id': 0,\n",
              "  'verb': 'came',\n",
              "  'subject': 'they',\n",
              "  'object': 'us',\n",
              "  'sentence': 'It was the spring of 1943 when they came for us.'},\n",
              " {'sent-id': 1,\n",
              "  'verb': 'living',\n",
              "  'subject': 'We',\n",
              "  'object': 'village',\n",
              "  'sentence': 'We were living in a small village near Krakow.'},\n",
              " {'sent-id': 2,\n",
              "  'verb': 'arrived',\n",
              "  'subject': 'soldiers',\n",
              "  'object': '',\n",
              "  'sentence': 'The soldiers arrived early in the morning, shouting.'},\n",
              " {'sent-id': 2,\n",
              "  'verb': 'shouting',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'The soldiers arrived early in the morning, shouting.'},\n",
              " {'sent-id': 3,\n",
              "  'verb': 'rounded',\n",
              "  'subject': 'They',\n",
              "  'object': 'everyone',\n",
              "  'sentence': 'They rounded everyone up and forced us onto crowded trains.'},\n",
              " {'sent-id': 3,\n",
              "  'verb': 'forced',\n",
              "  'subject': '',\n",
              "  'object': 'us',\n",
              "  'sentence': 'They rounded everyone up and forced us onto crowded trains.'},\n",
              " {'sent-id': 5,\n",
              "  'verb': 'know',\n",
              "  'subject': 'We',\n",
              "  'object': '',\n",
              "  'sentence': \"We didn't know where we were going, but the fear was palpable.\"},\n",
              " {'sent-id': 5,\n",
              "  'verb': 'going',\n",
              "  'subject': 'we',\n",
              "  'object': '',\n",
              "  'sentence': \"We didn't know where we were going, but the fear was palpable.\"},\n",
              " {'sent-id': 7,\n",
              "  'verb': 'arrived',\n",
              "  'subject': 'we',\n",
              "  'object': 'place',\n",
              "  'sentence': 'Finally, we arrived at a place with barbed wire fences and watchtowers.'},\n",
              " {'sent-id': 11,\n",
              "  'verb': 'saw',\n",
              "  'subject': 'I',\n",
              "  'object': 'father',\n",
              "  'sentence': 'I never saw my father again.'},\n",
              " {'sent-id': 12,\n",
              "  'verb': 'sent',\n",
              "  'subject': 'mother',\n",
              "  'object': 'camp',\n",
              "  'sentence': \"My mother and I were sent to the women's camp.\"},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'forced',\n",
              "  'subject': 'We',\n",
              "  'object': '',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'do',\n",
              "  'subject': '',\n",
              "  'object': 'labor',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'building',\n",
              "  'subject': '',\n",
              "  'object': 'roads',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 15,\n",
              "  'verb': 'clearing',\n",
              "  'subject': '',\n",
              "  'object': 'rubble',\n",
              "  'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              " {'sent-id': 17,\n",
              "  'verb': 'became',\n",
              "  'subject': 'mother',\n",
              "  'object': '',\n",
              "  'sentence': 'One day, my mother became very ill.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'tried',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'care',\n",
              "  'subject': '',\n",
              "  'object': 'her',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'was',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 18,\n",
              "  'verb': 'do',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              " {'sent-id': 19,\n",
              "  'verb': 'died',\n",
              "  'subject': 'She',\n",
              "  'object': '',\n",
              "  'sentence': 'She died a few weeks later.'},\n",
              " {'sent-id': 21,\n",
              "  'verb': 'blurred',\n",
              "  'subject': 'The days',\n",
              "  'object': 'weeks',\n",
              "  'sentence': 'The days blurred into weeks, weeks into months.'},\n",
              " {'sent-id': 23,\n",
              "  'verb': 'deemed',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              " {'sent-id': 23,\n",
              "  'verb': 'work',\n",
              "  'subject': '',\n",
              "  'object': '',\n",
              "  'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              " {'sent-id': 23,\n",
              "  'verb': 'sent',\n",
              "  'subject': 'those',\n",
              "  'object': 'chambers',\n",
              "  'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              " {'sent-id': 24,\n",
              "  'verb': 'know',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': \"I don't know how I survived.\"},\n",
              " {'sent-id': 24,\n",
              "  'verb': 'survived',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': \"I don't know how I survived.\"},\n",
              " {'sent-id': 27,\n",
              "  'verb': 'knew',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': 'The hunger, the cold, the constant fear, the loss of everything I ever knew.'},\n",
              " {'sent-id': 28,\n",
              "  'verb': 'carry',\n",
              "  'subject': 'I',\n",
              "  'object': '',\n",
              "  'sentence': \"It's a burden I carry every day.\"}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Another way to this is by uploading your file using the file icon in the left sidebar. Then, replace `\"example-text\"` with the name of your uploaded file and run the code cell.\n",
        "\n",
        "```python\n",
        "example_text = open(\"your-uploaded-file\", 'r').read()\n",
        "file_result = annotate_text(example_text)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iY0BiQkrcRVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotating a list of texts"
      ],
      "metadata": {
        "id": "v-NkvcFLE8H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = chunk_and_annotate_text(example_text, n_segments=5, file_id=\"sample\")\n",
        "results"
      ],
      "metadata": {
        "id": "3_pMriYiCTgx",
        "outputId": "c95f2d47-a2cc-4177-b62f-2655d3006928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entities': [{'start_char': 11, 'token': 'spring', 'tag': 'GEONOUN'},\n",
              "   {'start_char': 75, 'token': 'village', 'tag': 'GEONOUN'},\n",
              "   {'start_char': 88, 'token': 'Krakow', 'tag': 'PLACE'},\n",
              "   {'start_char': 117, 'token': 'early in the morning', 'tag': 'TIME'},\n",
              "   {'start_char': 235, 'token': 'days', 'tag': 'DATE'},\n",
              "   {'start_char': 244, 'token': 'nights', 'tag': 'DATE'}],\n",
              "  'verb_data': [{'sent-id': 0,\n",
              "    'verb': 'came',\n",
              "    'subject': 'they',\n",
              "    'object': 'us',\n",
              "    'sentence': 'It was the spring of 1943 when they came for us.'},\n",
              "   {'sent-id': 1,\n",
              "    'verb': 'living',\n",
              "    'subject': 'We',\n",
              "    'object': 'village',\n",
              "    'sentence': 'We were living in a small village near Krakow.'},\n",
              "   {'sent-id': 2,\n",
              "    'verb': 'arrived',\n",
              "    'subject': 'soldiers',\n",
              "    'object': '',\n",
              "    'sentence': 'The soldiers arrived early in the morning, shouting.'},\n",
              "   {'sent-id': 2,\n",
              "    'verb': 'shouting',\n",
              "    'subject': '',\n",
              "    'object': '',\n",
              "    'sentence': 'The soldiers arrived early in the morning, shouting.'},\n",
              "   {'sent-id': 3,\n",
              "    'verb': 'rounded',\n",
              "    'subject': 'They',\n",
              "    'object': 'everyone',\n",
              "    'sentence': 'They rounded everyone up and forced us onto crowded trains.'},\n",
              "   {'sent-id': 3,\n",
              "    'verb': 'forced',\n",
              "    'subject': '',\n",
              "    'object': 'us',\n",
              "    'sentence': 'They rounded everyone up and forced us onto crowded trains.'},\n",
              "   {'sent-id': 5,\n",
              "    'verb': 'know',\n",
              "    'subject': 'We',\n",
              "    'object': '',\n",
              "    'sentence': \"We didn't know where we were going, but the fear was palpable.\"},\n",
              "   {'sent-id': 5,\n",
              "    'verb': 'going',\n",
              "    'subject': 'we',\n",
              "    'object': '',\n",
              "    'sentence': \"We didn't know where we were going, but the fear was palpable.\"}],\n",
              "  'fileId': 'sample',\n",
              "  'segId': 1,\n",
              "  'segCount': 5},\n",
              " {'entities': [{'start_char': 59, 'token': 'watchtowers', 'tag': 'GEONOUN'},\n",
              "   {'start_char': 79, 'token': 'Auschwitz', 'tag': 'CAMP'},\n",
              "   {'start_char': 147, 'token': 'children', 'tag': 'FAMILY'},\n",
              "   {'start_char': 185, 'token': 'father', 'tag': 'FAMILY'},\n",
              "   {'start_char': 202, 'token': 'mother', 'tag': 'FAMILY'},\n",
              "   {'start_char': 240, 'token': 'camp', 'tag': 'GEONOUN'}],\n",
              "  'verb_data': [{'sent-id': 0,\n",
              "    'verb': 'arrived',\n",
              "    'subject': 'we',\n",
              "    'object': 'place',\n",
              "    'sentence': 'Finally, we arrived at a place with barbed wire fences and watchtowers.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'saw',\n",
              "    'subject': 'I',\n",
              "    'object': 'father',\n",
              "    'sentence': 'I never saw my father again.'},\n",
              "   {'sent-id': 5,\n",
              "    'verb': 'sent',\n",
              "    'subject': 'mother',\n",
              "    'object': 'camp',\n",
              "    'sentence': \"My mother and I were sent to the women's camp.\"}],\n",
              "  'fileId': 'sample',\n",
              "  'segId': 2,\n",
              "  'segCount': 5},\n",
              " {'entities': [{'start_char': 98, 'token': 'building', 'tag': 'GEONOUN'},\n",
              "   {'start_char': 146, 'token': 'mother', 'tag': 'FAMILY'}],\n",
              "  'verb_data': [{'sent-id': 2,\n",
              "    'verb': 'forced',\n",
              "    'subject': 'We',\n",
              "    'object': '',\n",
              "    'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              "   {'sent-id': 2,\n",
              "    'verb': 'do',\n",
              "    'subject': '',\n",
              "    'object': 'labor',\n",
              "    'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              "   {'sent-id': 2,\n",
              "    'verb': 'building',\n",
              "    'subject': '',\n",
              "    'object': 'roads',\n",
              "    'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              "   {'sent-id': 2,\n",
              "    'verb': 'clearing',\n",
              "    'subject': '',\n",
              "    'object': 'rubble',\n",
              "    'sentence': 'We were forced to do hard labor, building roads and clearing rubble.'},\n",
              "   {'sent-id': 3,\n",
              "    'verb': 'became',\n",
              "    'subject': 'mother',\n",
              "    'object': '',\n",
              "    'sentence': 'One day, my mother became very ill.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'tried',\n",
              "    'subject': 'I',\n",
              "    'object': '',\n",
              "    'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'care',\n",
              "    'subject': '',\n",
              "    'object': 'her',\n",
              "    'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'was',\n",
              "    'subject': '',\n",
              "    'object': '',\n",
              "    'sentence': 'I tried to care for her, but there was nothing I could do.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'do',\n",
              "    'subject': 'I',\n",
              "    'object': '',\n",
              "    'sentence': 'I tried to care for her, but there was nothing I could do.'}],\n",
              "  'fileId': 'sample',\n",
              "  'segId': 3,\n",
              "  'segCount': 5},\n",
              " {'entities': [{'start_char': 9, 'token': 'a few weeks later', 'tag': 'DATE'},\n",
              "   {'start_char': 41, 'token': 'The days', 'tag': 'DATE'},\n",
              "   {'start_char': 63, 'token': 'weeks', 'tag': 'DATE'},\n",
              "   {'start_char': 70, 'token': 'weeks', 'tag': 'DATE'},\n",
              "   {'start_char': 81, 'token': 'months', 'tag': 'DATE'}],\n",
              "  'verb_data': [{'sent-id': 0,\n",
              "    'verb': 'died',\n",
              "    'subject': 'She',\n",
              "    'object': '',\n",
              "    'sentence': 'She died a few weeks later.'},\n",
              "   {'sent-id': 2,\n",
              "    'verb': 'blurred',\n",
              "    'subject': 'The days',\n",
              "    'object': 'weeks',\n",
              "    'sentence': 'The days blurred into weeks, weeks into months.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'deemed',\n",
              "    'subject': '',\n",
              "    'object': '',\n",
              "    'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'work',\n",
              "    'subject': '',\n",
              "    'object': '',\n",
              "    'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'sent',\n",
              "    'subject': 'those',\n",
              "    'object': 'chambers',\n",
              "    'sentence': 'Selections were frequent, and those deemed too weak to work were sent to the gas chambers.'}],\n",
              "  'fileId': 'sample',\n",
              "  'segId': 4,\n",
              "  'segCount': 5},\n",
              " {'entities': [{'start_char': 124, 'token': 'years', 'tag': 'DATE'},\n",
              "   {'start_char': 230, 'token': 'every day', 'tag': 'DATE'}],\n",
              "  'verb_data': [{'sent-id': 0,\n",
              "    'verb': 'know',\n",
              "    'subject': 'I',\n",
              "    'object': '',\n",
              "    'sentence': \"I don't know how I survived.\"},\n",
              "   {'sent-id': 0,\n",
              "    'verb': 'survived',\n",
              "    'subject': 'I',\n",
              "    'object': '',\n",
              "    'sentence': \"I don't know how I survived.\"},\n",
              "   {'sent-id': 3,\n",
              "    'verb': 'knew',\n",
              "    'subject': 'I',\n",
              "    'object': '',\n",
              "    'sentence': 'The hunger, the cold, the constant fear, the loss of everything I ever knew.'},\n",
              "   {'sent-id': 4,\n",
              "    'verb': 'carry',\n",
              "    'subject': 'I',\n",
              "    'object': '',\n",
              "    'sentence': \"It's a burden I carry every day.\"}],\n",
              "  'fileId': 'sample',\n",
              "  'segId': 5,\n",
              "  'segCount': 5}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ToDo\n",
        "Additional features to include\n",
        "- Annotating a list of texts\n",
        "- Saving annotations to files (what format: csv, json, txt)\n",
        "- Emotion classification (LLM vs BERT-based)\n",
        "- Sentiment.\n",
        "- Geocoding\n",
        "- Create the `Lake District` and `Holocaust` modules?\n",
        "  - `Holocaust`:\n",
        "      - `journey` extraction\n",
        "      - `event` extraction\n",
        "  - `Lake District`:\n",
        "      - `nearness`\n",
        "      - `wild` and `picturesque`\n",
        "- Analysis\n",
        "- Visualization"
      ],
      "metadata": {
        "id": "Lda1ctcazsUL"
      }
    }
  ]
}